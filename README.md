# Student Performance Clustering App üéì

## Description

This project analyzes student performance metrics (STG, SCG, STR, LPR, PEG) using KMeans clustering to group students into different performance levels. It preprocesses the data using Power Transformation (Yeo-Johnson) and Standard Scaling before applying the clustering algorithm. The numerical cluster labels generated by KMeans are then mapped to descriptive performance levels: "very_low", "Low", "Middle", and "High" based on centroid analysis.

The repository includes a Gradio application (`app.py`) that allows users to input student metrics via sliders and receive a prediction for the student's performance level cluster.

---

## Files in this Repository üìÅ

* `data_student.csv`: The original dataset containing student performance metrics.
* `data-student.ipynb`: (Optional - if you include it) The Jupyter Notebook containing the analysis, preprocessing, model training, and evaluation steps.
* `student_clustering_pipeline.joblib`: The saved file containing the fitted PowerTransformer, StandardScaler, PCA object, and trained KMeans model.
* `app.py`: The Gradio application script to load the pipeline and run the interactive prediction interface.
* `README.md`: This file.
* (Optional) `requirements.txt`: A file listing necessary Python libraries.

---

## Setup & Installation üõ†Ô∏è

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/YOUR_USERNAME/YOUR_REPOSITORY_NAME.git](https://github.com/YOUR_USERNAME/YOUR_REPOSITORY_NAME.git)
    cd YOUR_REPOSITORY_NAME
    ```
2.  **Create a virtual environment (Recommended):**
    ```bash
    python -m venv venv
    # On Windows
    venv\Scripts\activate
    # On macOS/Linux
    source venv/bin/activate
    ```
3.  **Install required libraries:**
    ```bash
    pip install gradio pandas numpy scikit-learn joblib
    ```
    *(Alternatively, if you create a `requirements.txt` file, use `pip install -r requirements.txt`)*

---

## How to Run the App ‚ñ∂Ô∏è

1.  Make sure you are in the project's root directory in your terminal and your virtual environment is activated.
2.  Ensure the `student_clustering_pipeline.joblib` file is present in the directory.
3.  Run the Gradio application:
    ```bash
    python app.py
    ```
4.  Open the local URL provided in your terminal (usually `http://127.0.0.1:7860`) in your web browser.
5.  Use the sliders to input the student's metrics (values between 0.0 and 1.0).
6.  Click "Submit" to see the predicted performance level.

---

## Clustering & Label Mapping Logic üß†

* The numerical features (`STG`, `SCG`, `STR`, `LPR`, `PEG`) from `data_student.csv` are preprocessed to handle skewness (Yeo-Johnson Power Transformation) and scale differences (Standard Scaling).
* KMeans clustering is applied to the preprocessed data. Analysis suggested k=8 as the optimal number of clusters.
* The centroids (centers) of these 8 clusters are analyzed by transforming them back to the original data scale.
* An average performance score is calculated for each centroid.
* The 8 clusters are sorted based on their score and grouped into four descriptive labels ("very\_low", "Low", "Middle", "High"), with the two lowest-scoring clusters mapped to "very\_low", the next two to "Low", and so on.
* The Gradio app uses this mapping to translate the numerical cluster prediction from the KMeans model into a user-friendly performance level description.
